{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8f3b54d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Wikipedia page URL\n",
        "url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue'\n",
        "\n",
        "# Send GET request to the URL\n",
        "page = requests.get(url)\n",
        "\n",
        "# Parse the content using BeautifulSoup\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "# Find the table (the first one with class 'wikitable sortable')\n",
        "table = soup.find_all('table', class_='wikitable sortable')[0]\n",
        "\n",
        "# Extract column headers (the 'th' elements)\n",
        "column_titles = [title.text.strip() for title in table.find_all('th')]\n",
        "print(column_titles)\n",
        "\n",
        "# Extract table rows\n",
        "rows = table.find_all('tr')\n",
        "\n",
        "# Create an empty DataFrame with the column titles\n",
        "df = pd.DataFrame(columns=column_titles)\n",
        "\n",
        "# Loop through the table rows and extract the data\n",
        "for row in rows[1:]:  # Skip the header row\n",
        "    row_data = row.find_all('td')\n",
        "    if len(row_data) > 0:  # Skip empty rows\n",
        "        # Extract the text from each cell and clean it\n",
        "        individual_row_data = [data.text.strip() for data in row_data]\n",
        "        df.loc[len(df)] = individual_row_data\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n",
        "\n",
        "# Save to CSV (make sure the path is correct for your system)\n",
        "df.to_csv('companies.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
